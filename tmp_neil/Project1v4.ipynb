{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from utils import load_data, split_data\n",
    "from train import train, trial\n",
    "from metrics import compute_accuracy\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and test data\n",
    "train_data, test_data = load_data()\n",
    "\n",
    "# Split data in train-validation-test\n",
    "train_loader, valid_loader, test_loader = split_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, mode='baseline', verbose=True):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        ## Siamese block\n",
    "        self.conv1 = nn.Conv2d(1, 24, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(24, 49, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(14*14, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "        # Decision block\n",
    "        self.fc3 = nn.Linear(20, 10)\n",
    "        self.fc4 = nn.Linear(10, 1)\n",
    "        \n",
    "        # Regularizers\n",
    "        if mode == 'baseline':\n",
    "            self.drop = nn.Dropout(0)\n",
    "        elif mode == 'dropout':\n",
    "            self.drop = nn.Dropout(0.2)\n",
    "        else:\n",
    "            raise ValueError('Unknown mode. Try \"baseline\" or \"dropout\".')\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        # Activation fcns\n",
    "        self.relu = nn.ReLU()\n",
    "        self.selu = nn.SELU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'Parameters: {self.count_params()}')\n",
    "\n",
    "    def count_params(self):\n",
    "        return sum(p.numel() for p in self.parameters())\n",
    "    \n",
    "    def siamese_block(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x.unsqueeze(1))))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.relu(self.fc1(x.flatten(start_dim=1)))\n",
    "        x = self.drop(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.drop(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1, x2 = x.unbind(1)\n",
    "        \n",
    "        x1, x2 = self.siamese_block(x1), self.siamese_block(x2)\n",
    "        \n",
    "        # Dim x1: Nx1x10\n",
    "        aux = torch.stack([x1, x2], dim=1)\n",
    "        \n",
    "        # Dim aux: Nx2x10\n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        \n",
    "        # Dim x: Nx20\n",
    "        x = self.relu(self.fc3(x.flatten(start_dim=1)))\n",
    "        x = self.drop(x)\n",
    "        x = self.sigmoid(self.fc4(x))\n",
    "        return x.squeeze(), aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 37600\n"
     ]
    }
   ],
   "source": [
    "net = CNN(mode='dropout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Binary loss: 0.688, Auxiliary loss: 4.220, Validation loss: 2.761, \n",
      "Epoch 2/25, Binary loss: 0.680, Auxiliary loss: 3.375, Validation loss: 2.748, \n",
      "Epoch 3/25, Binary loss: 0.667, Auxiliary loss: 3.074, Validation loss: 2.727, \n",
      "Epoch 4/25, Binary loss: 0.669, Auxiliary loss: 2.878, Validation loss: 2.727, \n",
      "Epoch 5/25, Binary loss: 0.684, Auxiliary loss: 2.846, Validation loss: 2.685, \n",
      "Epoch 6/25, Binary loss: 0.653, Auxiliary loss: 2.712, Validation loss: 2.636, \n",
      "Epoch 7/25, Binary loss: 0.635, Auxiliary loss: 2.160, Validation loss: 2.593, \n",
      "Epoch 8/25, Binary loss: 0.611, Auxiliary loss: 2.019, Validation loss: 2.463, \n",
      "Epoch 9/25, Binary loss: 0.643, Auxiliary loss: 1.969, Validation loss: 2.386, \n",
      "Epoch 10/25, Binary loss: 0.583, Auxiliary loss: 2.427, Validation loss: 2.246, \n",
      "Epoch 11/25, Binary loss: 0.562, Auxiliary loss: 1.962, Validation loss: 2.128, \n",
      "Epoch 12/25, Binary loss: 0.587, Auxiliary loss: 1.815, Validation loss: 2.004, \n",
      "Epoch 13/25, Binary loss: 0.556, Auxiliary loss: 1.854, Validation loss: 1.884, \n",
      "Epoch 14/25, Binary loss: 0.426, Auxiliary loss: 1.961, Validation loss: 1.762, \n",
      "Epoch 15/25, Binary loss: 0.387, Auxiliary loss: 1.321, Validation loss: 1.627, \n",
      "Epoch 16/25, Binary loss: 0.439, Auxiliary loss: 1.985, Validation loss: 1.513, \n",
      "Epoch 17/25, Binary loss: 0.427, Auxiliary loss: 1.947, Validation loss: 1.451, \n",
      "Epoch 18/25, Binary loss: 0.253, Auxiliary loss: 1.713, Validation loss: 1.390, \n",
      "Epoch 19/25, Binary loss: 0.321, Auxiliary loss: 1.844, Validation loss: 1.291, \n",
      "Epoch 20/25, Binary loss: 0.327, Auxiliary loss: 1.811, Validation loss: 1.205, \n",
      "Epoch 21/25, Binary loss: 0.368, Auxiliary loss: 2.167, Validation loss: 1.196, \n",
      "Epoch 22/25, Binary loss: 0.293, Auxiliary loss: 1.591, Validation loss: 1.129, \n",
      "Epoch 23/25, Binary loss: 0.258, Auxiliary loss: 1.903, Validation loss: 1.068, \n",
      "Epoch 24/25, Binary loss: 0.376, Auxiliary loss: 1.363, Validation loss: 1.063, \n",
      "Epoch 25/25, Binary loss: 0.214, Auxiliary loss: 1.782, Validation loss: 1.085, \n",
      "13.81859278678894\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tr_losses = train(net, train_loader, valid_loader, alpha=1, alpha_decay=.9)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_accuracy(net, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 37600\n",
      "Trial 1/30... Training time: 13.36 s\n",
      "Loss: 0.0420, Train acc: 1.0000, Test acc: 0.8440\n",
      "Trial 2/30... Training time: 13.07 s\n",
      "Loss: 0.0845, Train acc: 1.0000, Test acc: 0.8330\n",
      "Trial 3/30... Training time: 13.09 s\n",
      "Loss: 0.0278, Train acc: 1.0000, Test acc: 0.8280\n",
      "Trial 4/30... Training time: 12.90 s\n",
      "Loss: 0.0373, Train acc: 1.0000, Test acc: 0.8380\n",
      "Trial 5/30... Training time: 13.09 s\n",
      "Loss: 0.3821, Train acc: 1.0000, Test acc: 0.8290\n",
      "Trial 6/30... Training time: 12.93 s\n",
      "Loss: 0.0305, Train acc: 1.0000, Test acc: 0.8460\n",
      "Trial 7/30... Training time: 12.92 s\n",
      "Loss: 0.0568, Train acc: 1.0000, Test acc: 0.8300\n",
      "Trial 8/30... Training time: 13.02 s\n",
      "Loss: 0.0489, Train acc: 1.0000, Test acc: 0.8300\n",
      "Trial 9/30... Training time: 12.93 s\n",
      "Loss: 0.0346, Train acc: 1.0000, Test acc: 0.8350\n",
      "Trial 10/30... Training time: 13.82 s\n",
      "Loss: 0.0588, Train acc: 1.0000, Test acc: 0.8450\n",
      "Trial 11/30... Training time: 14.87 s\n",
      "Loss: 0.0361, Train acc: 1.0000, Test acc: 0.8360\n",
      "Trial 12/30... Training time: 14.08 s\n",
      "Loss: 0.0645, Train acc: 1.0000, Test acc: 0.8370\n",
      "Trial 13/30... Training time: 13.86 s\n",
      "Loss: 0.0706, Train acc: 1.0000, Test acc: 0.8350\n",
      "Trial 14/30... Training time: 13.84 s\n",
      "Loss: 0.0361, Train acc: 1.0000, Test acc: 0.8320\n",
      "Trial 15/30... Training time: 15.32 s\n",
      "Loss: 0.1165, Train acc: 1.0000, Test acc: 0.8390\n",
      "Trial 16/30... Training time: 19.41 s\n",
      "Loss: 0.0566, Train acc: 1.0000, Test acc: 0.8380\n",
      "Trial 17/30... Training time: 19.09 s\n",
      "Loss: 0.0391, Train acc: 1.0000, Test acc: 0.8480\n",
      "Trial 18/30... Training time: 14.48 s\n",
      "Loss: 0.0389, Train acc: 1.0000, Test acc: 0.8380\n",
      "Trial 19/30... Training time: 14.03 s\n",
      "Loss: 0.0378, Train acc: 1.0000, Test acc: 0.8370\n",
      "Trial 20/30... Training time: 13.97 s\n",
      "Loss: 0.0526, Train acc: 1.0000, Test acc: 0.8400\n",
      "Trial 21/30... Training time: 15.35 s\n",
      "Loss: 0.0413, Train acc: 1.0000, Test acc: 0.8270\n",
      "Trial 22/30... Training time: 16.83 s\n",
      "Loss: 0.0512, Train acc: 1.0000, Test acc: 0.8300\n",
      "Trial 23/30... Training time: 17.04 s\n",
      "Loss: 0.0351, Train acc: 1.0000, Test acc: 0.8350\n",
      "Trial 24/30... Training time: 14.23 s\n",
      "Loss: 0.0268, Train acc: 1.0000, Test acc: 0.8270\n",
      "Trial 25/30... Training time: 15.11 s\n",
      "Loss: 0.0542, Train acc: 1.0000, Test acc: 0.8360\n",
      "Trial 26/30... Training time: 16.97 s\n",
      "Loss: 0.2080, Train acc: 0.9987, Test acc: 0.8310\n",
      "Trial 27/30... Training time: 15.26 s\n",
      "Loss: 0.0382, Train acc: 1.0000, Test acc: 0.8310\n"
     ]
    }
   ],
   "source": [
    "_, tr_accuracies, te_accuracies = trial(CNN(mode='baseline'), train_data, test_data, alpha=0, alpha_decay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train accuracy - mean: %.4f, std: %.4f, median: %.4f' % \n",
    "     (tr_accuracies.mean(), tr_accuracies.std(), tr_accuracies.median()))\n",
    "print('Test accuracy - mean: %.4f, std: %.4f, median: %.4f' % \n",
    "     (te_accuracies.mean(), te_accuracies.std(), te_accuracies.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(te_accuracies)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
