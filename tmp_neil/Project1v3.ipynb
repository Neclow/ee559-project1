{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from utils import load_data, split_data\n",
    "from metrics import compute_accuracy\n",
    "from torchsummary import summary\n",
    "from train import train, trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "torch.manual_seed(43)\n",
    "split = 5\n",
    "indices = torch.randperm(10)\n",
    "a_idx = indices[:split]\n",
    "b_idx = indices[split:]\n",
    "data = torch.tensor(list(range(10))).squeeze()\n",
    "\n",
    "a = SubsetRandomSampler(a_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlc_practical_prologue.py  Project1v3.ipynb  __pycache__\r\n",
      "metrics.py\t\t   Project1v4.ipynb  train.py\r\n",
      "Project1.tar.gz\t\t   proj.tar.gz\t     utils.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar: Cowardly refusing to create an empty archive\r\n",
      "Try 'tar --help' or 'tar --usage' for more information.\r\n"
     ]
    }
   ],
   "source": [
    "!tar chvfz proj.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(data, batch_size=1, sampler=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8])\n",
      "tensor([0])\n",
      "tensor([4])\n",
      "tensor([5])\n",
      "tensor([9])\n"
     ]
    }
   ],
   "source": [
    "for i in train_loader:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_indices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3683c0783dc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSubsetRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_indices' is not defined"
     ]
    }
   ],
   "source": [
    "t = SubsetRandomSampler(train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = load_data()\n",
    "train_loader, valid_loader, test_loader = split_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, hidden=128, mode='baseline', verbose=True):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(14*14, hidden)\n",
    "        self.fc2 = nn.Linear(hidden, 10)\n",
    "        self.fc3 = nn.Linear(20, 10)\n",
    "        self.fc4 = nn.Linear(10, 1)\n",
    "        \n",
    "        if mode == 'baseline':\n",
    "            self.drop = nn.Dropout(0)\n",
    "        elif mode == 'dropout':\n",
    "            self.drop = nn.Dropout(0.2)\n",
    "        else:\n",
    "            raise ValueError('Unknown mode. Try \"baseline\" or \"dropout\"')\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'Parameters: {self.count_params()}')\n",
    "\n",
    "    def count_params(self):\n",
    "        return sum(p.numel() for p in self.parameters())\n",
    "    \n",
    "    def forward(self, x):   \n",
    "        x = self.relu(self.fc1(x.flatten(start_dim=2)))\n",
    "        x = self.drop(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.drop(x)\n",
    "        \n",
    "        aux = x\n",
    "\n",
    "        x = self.relu(self.fc3(x.flatten(start_dim=1)))\n",
    "        x = self.drop(x)\n",
    "        x = self.sigmoid(self.fc4(x))\n",
    "        return x.squeeze(), aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 26727\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1               [-1, 2, 128]          25,216\n",
      "              ReLU-2               [-1, 2, 128]               0\n",
      "           Dropout-3               [-1, 2, 128]               0\n",
      "            Linear-4                [-1, 2, 10]           1,290\n",
      "              ReLU-5                [-1, 2, 10]               0\n",
      "           Dropout-6                [-1, 2, 10]               0\n",
      "            Linear-7                   [-1, 10]             210\n",
      "              ReLU-8                   [-1, 10]               0\n",
      "           Dropout-9                   [-1, 10]               0\n",
      "           Linear-10                    [-1, 1]              11\n",
      "          Sigmoid-11                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 26,727\n",
      "Trainable params: 26,727\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.10\n",
      "Estimated Total Size (MB): 0.11\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "summary(net, (2, 14, 14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Binary loss: 0.680, Auxiliary loss: 3.805, Validation loss: 2.741, \n",
      "Epoch 2/25, Binary loss: 0.683, Auxiliary loss: 2.887, Validation loss: 2.653, \n",
      "Epoch 3/25, Binary loss: 0.669, Auxiliary loss: 2.665, Validation loss: 2.564, \n",
      "Epoch 4/25, Binary loss: 0.669, Auxiliary loss: 2.668, Validation loss: 2.474, \n",
      "Epoch 5/25, Binary loss: 0.596, Auxiliary loss: 2.328, Validation loss: 2.397, \n",
      "Epoch 6/25, Binary loss: 0.568, Auxiliary loss: 2.257, Validation loss: 2.315, \n",
      "Epoch 7/25, Binary loss: 0.548, Auxiliary loss: 2.004, Validation loss: 2.213, \n",
      "Epoch 8/25, Binary loss: 0.529, Auxiliary loss: 1.970, Validation loss: 2.135, \n",
      "Epoch 9/25, Binary loss: 0.548, Auxiliary loss: 2.245, Validation loss: 2.049, \n",
      "Epoch 10/25, Binary loss: 0.509, Auxiliary loss: 2.222, Validation loss: 1.969, \n",
      "Epoch 11/25, Binary loss: 0.518, Auxiliary loss: 2.251, Validation loss: 1.895, \n",
      "Epoch 12/25, Binary loss: 0.476, Auxiliary loss: 1.754, Validation loss: 1.833, \n",
      "Epoch 13/25, Binary loss: 0.420, Auxiliary loss: 2.094, Validation loss: 1.770, \n",
      "Epoch 14/25, Binary loss: 0.444, Auxiliary loss: 1.596, Validation loss: 1.740, \n",
      "Epoch 15/25, Binary loss: 0.514, Auxiliary loss: 2.104, Validation loss: 1.695, \n",
      "Epoch 16/25, Binary loss: 0.426, Auxiliary loss: 1.726, Validation loss: 1.665, \n",
      "Epoch 17/25, Binary loss: 0.536, Auxiliary loss: 2.031, Validation loss: 1.614, \n",
      "Epoch 18/25, Binary loss: 0.465, Auxiliary loss: 1.961, Validation loss: 1.560, \n",
      "Epoch 19/25, Binary loss: 0.451, Auxiliary loss: 2.261, Validation loss: 1.538, \n",
      "Epoch 20/25, Binary loss: 0.461, Auxiliary loss: 2.081, Validation loss: 1.505, \n",
      "Epoch 21/25, Binary loss: 0.457, Auxiliary loss: 1.881, Validation loss: 1.469, \n",
      "Epoch 22/25, Binary loss: 0.532, Auxiliary loss: 1.890, Validation loss: 1.410, \n",
      "Epoch 23/25, Binary loss: 0.400, Auxiliary loss: 2.198, Validation loss: 1.379, \n",
      "Epoch 24/25, Binary loss: 0.340, Auxiliary loss: 1.885, Validation loss: 1.390, \n",
      "Epoch 25/25, Binary loss: 0.370, Auxiliary loss: 1.820, Validation loss: 1.387, \n",
      "4.979055404663086\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "net = Net(mode='dropout', verbose=False)\n",
    "tr_losses = train(net, train_loader, valid_loader, alpha=1, alpha_decay=.9, n_epochs=25)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_accuracy(net, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 26727\n",
      "Trial 1/30... Training time: 4.36 s\n",
      "Loss: 4.577, Train acc: 0.966, Test acc: 0.861\n",
      "Trial 2/30... Training time: 4.74 s\n",
      "Loss: 5.610, Train acc: 0.941, Test acc: 0.846\n",
      "Trial 3/30... Training time: 4.19 s\n",
      "Loss: 4.799, Train acc: 0.965, Test acc: 0.865\n",
      "Trial 4/30... Training time: 4.36 s\n",
      "Loss: 5.088, Train acc: 0.954, Test acc: 0.862\n",
      "Trial 5/30... Training time: 4.40 s\n",
      "Loss: 4.384, Train acc: 0.970, Test acc: 0.869\n",
      "Trial 6/30... Training time: 4.65 s\n",
      "Loss: 4.880, Train acc: 0.957, Test acc: 0.848\n",
      "Trial 7/30... Training time: 5.19 s\n",
      "Loss: 5.933, Train acc: 0.941, Test acc: 0.858\n",
      "Trial 8/30... Training time: 6.63 s\n",
      "Loss: 5.663, Train acc: 0.964, Test acc: 0.874\n",
      "Trial 9/30... Training time: 8.25 s\n",
      "Loss: 5.223, Train acc: 0.950, Test acc: 0.817\n",
      "Trial 10/30... Training time: 7.98 s\n",
      "Loss: 5.518, Train acc: 0.938, Test acc: 0.856\n",
      "Trial 11/30... Training time: 5.46 s\n",
      "Loss: 4.716, Train acc: 0.961, Test acc: 0.873\n",
      "Trial 12/30... Training time: 5.12 s\n",
      "Loss: 5.267, Train acc: 0.964, Test acc: 0.854\n",
      "Trial 13/30... Training time: 5.32 s\n",
      "Loss: 4.701, Train acc: 0.944, Test acc: 0.860\n",
      "Trial 14/30... Training time: 4.92 s\n",
      "Loss: 5.398, Train acc: 0.944, Test acc: 0.853\n",
      "Trial 15/30... Training time: 7.49 s\n",
      "Loss: 4.500, Train acc: 0.964, Test acc: 0.872\n",
      "Trial 16/30... Training time: 5.77 s\n",
      "Loss: 4.961, Train acc: 0.959, Test acc: 0.867\n",
      "Trial 17/30... Training time: 4.92 s\n",
      "Loss: 4.211, Train acc: 0.964, Test acc: 0.868\n",
      "Trial 18/30... Training time: 5.00 s\n",
      "Loss: 4.785, Train acc: 0.966, Test acc: 0.869\n",
      "Trial 19/30... Training time: 4.79 s\n",
      "Loss: 5.102, Train acc: 0.959, Test acc: 0.865\n",
      "Trial 20/30... Training time: 5.49 s\n",
      "Loss: 4.889, Train acc: 0.957, Test acc: 0.870\n",
      "Trial 21/30... Training time: 5.18 s\n",
      "Loss: 5.174, Train acc: 0.952, Test acc: 0.875\n",
      "Trial 22/30... Training time: 5.78 s\n",
      "Loss: 5.051, Train acc: 0.960, Test acc: 0.858\n",
      "Trial 23/30... Training time: 4.30 s\n",
      "Loss: 4.864, Train acc: 0.952, Test acc: 0.860\n",
      "Trial 24/30... Training time: 4.38 s\n",
      "Loss: 4.916, Train acc: 0.966, Test acc: 0.868\n",
      "Trial 25/30... Training time: 4.42 s\n",
      "Loss: 5.843, Train acc: 0.951, Test acc: 0.873\n",
      "Trial 26/30... Training time: 7.33 s\n",
      "Loss: 6.057, Train acc: 0.910, Test acc: 0.818\n",
      "Trial 27/30... Training time: 5.01 s\n",
      "Loss: 5.421, Train acc: 0.967, Test acc: 0.871\n",
      "Trial 28/30... Training time: 4.52 s\n",
      "Loss: 5.720, Train acc: 0.959, Test acc: 0.867\n",
      "Trial 29/30... Training time: 5.07 s\n",
      "Loss: 4.335, Train acc: 0.964, Test acc: 0.867\n",
      "Trial 30/30... Training time: 4.91 s\n",
      "Loss: 7.540, Train acc: 0.915, Test acc: 0.825\n"
     ]
    }
   ],
   "source": [
    "all_losses, tr_accuracies, te_accuracies = trial(Net(mode='dropout'), train_data, test_data, \n",
    "                                                 n_trials=30, alpha=0.25, alpha_decay=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy - mean: 0.9542, std: 0.0143, median: 0.9588\n",
      "Test accuracy - mean: 0.8596, std: 0.0154, median: 0.8650\n"
     ]
    }
   ],
   "source": [
    "print('Train accuracy - mean: %.4f, std: %.4f, median: %.4f' % \n",
    "     (tr_accuracies.mean(), tr_accuracies.std(), tr_accuracies.median()))\n",
    "print('Test accuracy - mean: %.4f, std: %.4f, median: %.4f' % \n",
    "     (te_accuracies.mean(), te_accuracies.std(), te_accuracies.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(te_accuracies)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
